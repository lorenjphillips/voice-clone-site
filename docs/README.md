<img width="1200" alt="cb-big2" src="https://github.com/user-attachments/assets/bd8c5f03-e91d-4ee5-b680-57355da204d1" />

# Chatterbox TTS

[![Alt Text](https://img.shields.io/badge/listen-demo_samples-blue)](https://resemble-ai.github.io/chatterbox_demopage/)
[![Alt Text](https://huggingface.co/datasets/huggingface/badges/resolve/main/open-in-hf-spaces-sm.svg)](https://huggingface.co/spaces/ResembleAI/Chatterbox)
[![Alt Text](https://static-public.podonos.com/badges/insight-on-pdns-sm-dark.svg)](https://podonos.com/resembleai/chatterbox)
[![Discord](https://img.shields.io/discord/1377773249798344776?label=join%20discord&logo=discord&style=flat)](https://discord.gg/XqS7RxUp)

_Made with ♥️ by <a href="https://resemble.ai" target="_blank"><img width="100" alt="resemble-logo-horizontal" src="https://github.com/user-attachments/assets/35cf756b-3506-4943-9c72-c05ddfa4e525" /></a>

We're excited to introduce Chatterbox, [Resemble AI's](https://resemble.ai) first production-grade open source TTS model. Licensed under MIT, Chatterbox has been benchmarked against leading closed-source systems like ElevenLabs, and is consistently preferred in side-by-side evaluations.

Whether you're working on memes, videos, games, or AI agents, Chatterbox brings your content to life. It's also the first open source TTS model to support **emotion exaggeration control**, a powerful feature that makes your voices stand out. Try it now on our [Hugging Face Gradio app.](https://huggingface.co/spaces/ResembleAI/Chatterbox)

If you like the model but need to scale or tune it for higher accuracy, check out our competitively priced TTS service (<a href="https://resemble.ai">link</a>). It delivers reliable performance with ultra-low latency of sub 200ms—ideal for production use in agents, applications, or interactive media.

# Key Details
- SoTA zeroshot TTS
- 0.5B Llama backbone
- Unique exaggeration/intensity control
- Ultra-stable with alignment-informed inference
- Trained on 0.5M hours of cleaned data
- Watermarked outputs
- Easy voice conversion script
- [Outperforms ElevenLabs](https://podonos.com/resembleai/chatterbox)

# Tips
- **General Use (TTS and Voice Agents):**
  - The default settings (`exaggeration=0.5`, `cfg_weight=0.5`) work well for most prompts.
  - If the reference speaker has a fast speaking style, lowering `cfg_weight` to around `0.3` can improve pacing.

- **Expressive or Dramatic Speech:**
  - Try lower `cfg_weight` values (e.g. `~0.3`) and increase `exaggeration` to around `0.7` or higher.
  - Higher `exaggeration` tends to speed up speech; reducing `cfg_weight` helps compensate with slower, more deliberate pacing.


# Installation
```
pip install chatterbox-tts
```


# Usage
```python
import torchaudio as ta
from chatterbox.tts import ChatterboxTTS

model = ChatterboxTTS.from_pretrained(device="cuda")

text = "Ezreal and Jinx teamed up with Ahri, Yasuo, and Teemo to take down the enemy's Nexus in an epic late-game pentakill."
wav = model.generate(text)
ta.save("test-1.wav", wav, model.sr)

# If you want to synthesize with a different voice, specify the audio prompt
AUDIO_PROMPT_PATH="YOUR_FILE.wav"
wav = model.generate(text, audio_prompt_path=AUDIO_PROMPT_PATH)
ta.save("test-2.wav", wav, model.sr)
```
See `example_tts.py` for more examples.

# Acknowledgements
- [Cosyvoice](https://github.com/FunAudioLLM/CosyVoice)
- [Real-Time-Voice-Cloning](https://github.com/CorentinJ/Real-Time-Voice-Cloning)
- [HiFT-GAN](https://github.com/yl4579/HiFTNet)
- [Llama 3](https://github.com/meta-llama/llama3)
- [S3Tokenizer](https://github.com/xingchensong/S3Tokenizer)

# Built-in PerTh Watermarking for Responsible AI

Every audio file generated by Chatterbox includes [Resemble AI's Perth (Perceptual Threshold) Watermarker](https://github.com/resemble-ai/perth) - imperceptible neural watermarks that survive MP3 compression, audio editing, and common manipulations while maintaining nearly 100% detection accuracy.

# Official Discord

👋 Join us on [Discord](https://discord.gg/XqS7RxUp) and let's build something awesome together!

# Disclaimer
Don't use this model to do bad things. Prompts are sourced from freely available data on the internet.

# 🎙️ Voice Clone Site

A modern voice cloning web application built with Chatterbox TTS. Features a React TypeScript frontend with a Python FastAPI backend for natural-sounding speech generation.

## ✨ Features

- **🎨 Modern React Frontend**: TypeScript + Tailwind CSS + Shadcn/ui components
- **🎙️ High-Quality TTS**: Neural text-to-speech with natural voice synthesis
- **🎭 Emotion Control**: Adjust exaggeration and pace for different speaking styles  
- **🔊 Voice Cloning**: Upload reference audio to clone specific voices (optional)
- **🌙 Dark/Light Mode**: Beautiful themes with smooth transitions
- **📱 Mobile Responsive**: Works perfectly on all devices
- **🎵 Built-in Audio Player**: Play and download generated audio
- **🔄 Real-time API**: RESTful API with live health monitoring
- **🚀 Production Ready**: Optimized for deployment

## 🚀 Quick Start (Local Development)

### Prerequisites
- Python 3.8+ 
- Node.js 18+ (for React frontend)
- macOS (ARM64 optimized) or Linux

### Setup
```bash
# Clone the repo
git clone <your-repo-url>
cd voice-clone-site

# Install Python dependencies  
pip install -r requirements.txt

# Install frontend dependencies
cd frontend
npm install
cd ..

# Start both backend and frontend
python start_dev.py
```

This will start:
- **Backend API**: `http://localhost:8000`
- **React Frontend**: `http://localhost:5173`

Open `http://localhost:5173` in your browser to use the application.

## 🌐 Production Deployment

### Backend (Render)
1. Push this repo to GitHub
2. Connect to Render
3. Deploy as Web Service with:
   - Build: `pip install -r requirements.txt`
   - Start: `python api_server.py`
   - Environment: `PYTORCH_ENABLE_MPS_FALLBACK=1`

### Frontend (Vercel)  
1. Deploy the `/frontend` directory to Vercel
2. Set environment variable: `VITE_API_URL=https://your-api.onrender.com`
3. Vercel will auto-detect Vite and build the React app

## 📡 API Usage

### Generate TTS
```bash
curl -X POST "https://your-api.onrender.com/tts" \
  -H "Content-Type: application/json" \
  -d '{
    "text": "Hello, this is a test!",
    "exaggeration": 0.7,
    "temperature": 0.8,
    "cfg_weight": 0.5
  }'
```

### Generate TTS with Voice Cloning
```bash
curl -X POST "https://your-api.onrender.com/tts-with-voice" \
  -F "text=Hello, this is a test!" \
  -F "exaggeration=0.7" \
  -F "temperature=0.8" \
  -F "cfg_weight=0.5" \
  -F "audio_file=@reference.wav"
```

### Response
```json
{
  "audio_base64": "UklGRiQHAABXQVZFZm10...",
  "sample_rate": 24000,
  "message": "TTS generation successful"
}
```

## 🔧 Configuration

### Voice Settings
- **Exaggeration** (0.25-2.0): Controls emotional expression
  - 0.5 = Neutral (default)
  - 0.7+ = More expressive
  - 1.5+ = Very dramatic

- **CFG/Pace** (0.0-1.0): Controls speaking pace
  - 0.5 = Normal pace (default)  
  - 0.3 = Slower, more deliberate
  - 0.7+ = Faster speech

- **Temperature** (0.05-2.0): Controls voice variation
  - 0.8 = Natural variation (default)
  - Lower = More consistent
  - Higher = More varied

## 🎯 Use Cases

- **Content Creation**: Generate voiceovers for videos
- **Accessibility**: Convert text to speech for visually impaired users
- **E-learning**: Create narrated educational content
- **Podcasts**: Generate intro/outro segments
- **Voice Assistants**: Power conversational AI applications
- **Gaming**: Generate dynamic character voices

## 📁 Project Structure

```
voice-clone-site/
├── api_server.py           # FastAPI backend
├── start_dev.py           # Development startup script
├── frontend/              # React TypeScript frontend
│   ├── src/
│   │   ├── components/    # UI components
│   │   ├── pages/        # Page components
│   │   ├── lib/          # API client & utilities
│   │   └── hooks/        # Custom React hooks
│   ├── package.json      # Frontend dependencies
│   └── vite.config.ts    # Vite configuration
├── legacy/               # Deprecated HTML frontend
├── test_api.py          # API testing
├── requirements.txt     # Python dependencies
├── render.yaml         # Render deployment config
└── README.md           # This file
```

## ⚡ Performance

- **Local (Mac)**: ~15-20 seconds per generation
- **Production**: ~10-15 seconds (with GPU acceleration)
- **Concurrent Users**: Supports multiple simultaneous requests
- **Audio Quality**: 24kHz sample rate, broadcast quality

## 🆕 Frontend Features

The React frontend provides:
- **TypeScript**: Full type safety and better developer experience
- **Component Architecture**: Reusable, maintainable UI components
- **Real-time Updates**: Live API health monitoring
- **Error Handling**: Comprehensive error states and user feedback
- **Audio Controls**: Built-in player with download functionality
- **Theme Support**: Dark/light mode with system preference detection
- **Mobile First**: Responsive design that works on all screen sizes
